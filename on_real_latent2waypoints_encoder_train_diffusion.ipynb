{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from models.resnet import ResNetVAE\n",
    "from utils_.utils import from_sim_get_poses_n_gripper\n",
    "from utils_.plotting import plot_waypoints_and_initial_image\n",
    "from utils_.waypoint_extraction import pickplace_task_waypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device Name: {torch.cuda.get_device_name(device)}\" if device.type == \"cuda\" else \"Using cpu\")\n",
    "DATA_PATH = \"./datasets/small_sim_recs\"\n",
    "IMAGE_RESIZE = 32\n",
    "LATENT_DIM = 16\n",
    "DATAPOINT_COUNT = 200\n",
    "AE_PATH = \"./logs/models/VAE_2024-10-25_16:30/pth/epoch_400.pth\"\n",
    "L2W_PATH = \"./logs/models/mlp_2024-10-21_16:47/pth/epoch_2000.pth\"\n",
    "dirs = os.listdir(DATA_PATH)\n",
    "im_paths = [f\"{DATA_PATH}/{dir}/images/0000.jpg\" for dir in dirs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the input data: latent representation of initial scene images\n",
    "X = []\n",
    "for i, im_path in tqdm(enumerate(im_paths)):\n",
    "    image = cv2.imread(im_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (IMAGE_RESIZE, IMAGE_RESIZE))\n",
    "    image = image/255.0\n",
    "    image = np.transpose(image, (2, 0, 1))  # HWC to CHW\n",
    "    X.append(image)\n",
    "    if i == DATAPOINT_COUNT-1: break\n",
    "\n",
    "X = np.array(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Create output data: waypoint collections from the paths\n",
    "ways = []\n",
    "for i, ep_path in tqdm(enumerate(dirs)):\n",
    "    if i == DATAPOINT_COUNT-1: break\n",
    "    pos, quat, gripper_widths = from_sim_get_poses_n_gripper(f\"{DATA_PATH}/{ep_path}/proprioceptives.txt\")\n",
    "    ways.append(pickplace_task_waypoints(pos, gripper_widths))\n",
    "ways = np.array(ways)\n",
    "\n",
    "y = ways.reshape(ways.shape[0], -1)\n",
    "del ways\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float)\n",
    "X_val_tensor = torch.tensor(X_test, dtype=torch.float)\n",
    "y_val_tensor = torch.tensor(y_test, dtype=torch.float)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class MLPdc(nn.Module):\n",
    "  \n",
    "    def __init__(self, input_dim: int, output_dim: int, hidden_layers: list[int]=[256, 256, 256]):\n",
    "        super(MLPdc, self).__init__()\n",
    "        layers = []\n",
    "        self.output_dim = output_dim\n",
    "        last_dim = input_dim + output_dim + 1\n",
    "        for size in hidden_layers:\n",
    "            layers.append(nn.Linear(last_dim, size))\n",
    "            layers.append(nn.ReLU())\n",
    "            last_dim = size\n",
    "\n",
    "        layers.append(nn.Linear(last_dim, output_dim))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "        self.model_params = {\n",
    "            'input_size': input_dim,\n",
    "        }\n",
    "\n",
    "        self.path = \".\"\n",
    "\n",
    "    def generate_log_data_path(self):\n",
    "        current_time = datetime.now().strftime(\"%Y-%m-%d_%H:%M\")\n",
    "        self.path = f\"./logs/models/diffuser-mlp_{current_time}\"\n",
    "        if not os.path.exists(f\"{self.path}/pth\"):\n",
    "            os.makedirs(f\"{self.path}/pth\")\n",
    "\n",
    "    def log_model(self):\n",
    "        self.generate_log_data_path()\n",
    "        with open(f'{self.path}/model_params.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.model_params, f)\n",
    "    \n",
    "    def save(self, epoch: int):\n",
    "        file_name = f\"{self.path}/pth/epoch_{epoch}.pth\"\n",
    "        torch.save(self.state_dict(), file_name)\n",
    "\n",
    "    def forward(self, c, x, t):\n",
    "        x = torch.concat([x, c, t], axis=-1)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "    \n",
    "    def sample(self, conditioning: np.ndarray, device: str, n_steps: int=100):\n",
    "        n_samples = conditioning.shape[0]\n",
    "        x_t = torch.randn((n_samples, self.output_dim)).to(device)\n",
    "        \n",
    "        for i in range(n_steps):\n",
    "            x_t += torch.randn((n_samples, self.output_dim)).to(device) * .001\n",
    "\n",
    "            # t = torch.zeros((n_samples, 1)).to(device) + i / n_steps\n",
    "            t = torch.ones((n_samples, 1)).to(device)\n",
    "\n",
    "            noise_prediction = self(conditioning, x_t, t)\n",
    "            # noise_prediction /= n_steps - i\n",
    "            noise_prediction /= n_steps\n",
    "            x_t -= noise_prediction\n",
    "\n",
    "        return x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ResNetVAE(latent_dim=LATENT_DIM, in_channels=3).to(device=device)\n",
    "mlp_model = MLPdc(LATENT_DIM, y_train.shape[1], hidden_layers=[256, 128]).to(device)\n",
    "\n",
    "lr=1e-4\n",
    "n_epochs=2_000\n",
    "recontruction_importance = .00006  # Does this change anything?\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(mlp_model.parameters()) + list(encoder.parameters()),\n",
    "    lr=lr\n",
    ")\n",
    "\n",
    "mlp_model.to(device)\n",
    "encoder.to(device)\n",
    "train_losses_ways = []\n",
    "train_losses_imgs = []\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "def vae_loss(reconstructed, original, mu, log_var, beta):\n",
    "    recon_loss = F.mse_loss(reconstructed, original, reduction='sum')\n",
    "    kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return recon_loss + beta * kl_div\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    # Train step\n",
    "    encoder.train()\n",
    "    mlp_model.train()\n",
    "    train_loss_waypoints = 0\n",
    "    train_loss_reconstruction = 0\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Image recontruction\n",
    "        latent_image, logvar = encoder.encoder(X)\n",
    "        z = encoder.reparameterize(latent_image, logvar)\n",
    "        reconstructed = encoder.decoder(z)\n",
    "\n",
    "        # Waypoint prediction\n",
    "        with torch.no_grad():\n",
    "            t = torch.rand(size=(y.shape[0], 1), device=device)\n",
    "            noise = torch.randn(*y.shape, device=device)\n",
    "            model_in = y * t + noise * ( torch.ones(size=(y.shape[0], 1), device=device) - t )\n",
    "            \n",
    "        out = mlp_model(latent_image, model_in, t)\n",
    "\n",
    "        # Compute losses\n",
    "        loss_waypoints = loss_fn(noise, out)\n",
    "        loss_reconstruction = recontruction_importance * vae_loss(reconstructed, X, latent_image, logvar, beta=.1)\n",
    "        loss = loss_reconstruction + loss_waypoints\n",
    "\n",
    "        train_loss_waypoints += loss_waypoints.item()\n",
    "        train_loss_reconstruction += loss_reconstruction.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss_waypoints /= len(train_loader)\n",
    "    train_loss_reconstruction /= len(train_loader)\n",
    "    train_losses_ways.append(train_loss_waypoints)\n",
    "    train_losses_imgs.append(train_loss_reconstruction)\n",
    "\n",
    "    # Print losses for this epoch\n",
    "    print(f\"Epoch {epoch + 1},\\t Train Loss waypoints: {train_loss_waypoints:.6f}, Train Loss images: {train_loss_reconstruction:.6f}\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_count = 10\n",
    "rand_images = np.array([val_dataset[np.random.randint(0, len(val_dataset))][0] for _ in range(example_count)])\n",
    "pred_images = encoder.forward_clean(torch.Tensor(rand_images).to(device))\n",
    "\n",
    "fig, axes = plt.subplots(example_count, 2, figsize=(15, 50))\n",
    "\n",
    "for i in range(example_count):\n",
    "    image = np.transpose(rand_images[i], (1, 2, 0))\n",
    "    axes[i, 0].imshow(image)\n",
    "    axes[i, 1].imshow(pred_images[i])\n",
    "\n",
    "    axes[i, 0].axis('off')\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    if i:\n",
    "        latent_images, _ = encoder.encode(torch.Tensor(X_test).to(device))\n",
    "        y_pred = mlp_model.sample(latent_images, device).cpu().detach().numpy()\n",
    "        errors = y_test - y_pred\n",
    "    else:\n",
    "        latent_images, _ = encoder.encode(torch.Tensor(X_train).to(device))\n",
    "        y_pred = mlp_model.sample(latent_images, device).cpu().detach().numpy()\n",
    "        errors = y_train - y_pred\n",
    "    \n",
    "    errors = errors[:, :2]\n",
    "    errors = [np.linalg.norm(e) for e in errors]\n",
    "    mean_error = sum(errors)/len(errors)\n",
    "    devs = [abs(e-mean_error) for e in errors]\n",
    "    dev_error = sum(devs)/len(devs)\n",
    "\n",
    "    max_error = .015\n",
    "    total_wins = 0\n",
    "    for e in errors:\n",
    "        if e < max_error:\n",
    "            total_wins += 1\n",
    "\n",
    "    if i:\n",
    "        print(\"Test avg. dist. from desired point (m): \", mean_error)\n",
    "        print(\"Test avg. dev. from desired point (m): \", dev_error)\n",
    "        print(f\"Success rate: {(total_wins/len(errors)*100):.2f}%\")\n",
    "    else:\n",
    "        print(\"Train avg. dist. from desired point (m): \", mean_error)\n",
    "        print(\"Train avg. dev. from desired point (m): \", dev_error)\n",
    "    print(\"+--------------------------------------------------------------+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_count = 6\n",
    "rand_indices = np.random.choice(list(range(len(X_test))), size=example_count)\n",
    "\n",
    "imgs = X_test[rand_indices]\n",
    "\n",
    "target_waypoints = y_test[rand_indices].reshape(6, 3, 3)\n",
    "\n",
    "latent_images, _ = encoder.encode(torch.Tensor(imgs).to(device))\n",
    "imgs = np.transpose(imgs, (0, 2, 3, 1))\n",
    "pred_waypoints = mlp_model.sample(latent_images, device).cpu().detach().numpy()\n",
    "pred_waypoints = pred_waypoints.reshape(6, 3, 3)\n",
    "\n",
    "plot_waypoints_and_initial_image(pred_waypoints, target_waypoints, imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robocup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
